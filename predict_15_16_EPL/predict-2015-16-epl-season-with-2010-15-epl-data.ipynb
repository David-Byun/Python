{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":17,"outputs":[{"output_type":"stream","text":"/kaggle/input/result-england1516/result_england1516.csv\n/kaggle/input/epl-data/totalengland.csv\n/kaggle/input/soccer/database.sqlite\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom pandas.io.parsers import read_csv\n\nmodel = tf.compat.v1.global_variables_initializer()\ndata = read_csv('/kaggle/input/epl-data/totalengland.csv', sep=',')\nxy = np.array(data, dtype=np.float32)\nprint(xy)","execution_count":18,"outputs":[{"output_type":"stream","text":"[[ 70.  45.  45. ...  37.  41.  80.]\n [ 70.  60.  56. ...  33.  36.  71.]\n [ 70.  60.  55. ...  33.  27.  71.]\n ...\n [ 56.  51.  54. ...  51. -18.  35.]\n [ 48.  74.  72. ...  53. -25.  33.]\n [ 52.  53.  53. ...  73. -31.  30.]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data = xy[:, 0:-1]\ny_data = xy[:,[-1]]\nprint(x_data)","execution_count":19,"outputs":[{"output_type":"stream","text":"[[ 70.  45.  45. ...  78.  37.  41.]\n [ 70.  60.  56. ...  69.  33.  36.]\n [ 70.  60.  55. ...  60.  33.  27.]\n ...\n [ 56.  51.  54. ...  33.  51. -18.]\n [ 48.  74.  72. ...  28.  53. -25.]\n [ 52.  53.  53. ...  42.  73. -31.]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.compat.v1.disable_eager_execution()\nX = tf.compat.v1.placeholder(tf.float32, shape=[None,14])\nY = tf.compat.v1.placeholder(tf.float32, shape=[None, 1])\nW = tf.Variable(tf.random.normal([14,1]), name=\"weight\")\nb = tf.Variable(tf.random.normal([1]), name=\"bias\")","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hypothesis = tf.matmul(X,W) + b","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost = tf.reduce_mean(tf.square(hypothesis - Y))","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.000005)\ntrain = optimizer.minimize(cost)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sess = tf.compat.v1.Session()\nsess.run(tf.compat.v1.global_variables_initializer())","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for step in range(100001):\n    cost_, hypo_, _=sess.run([cost,hypothesis,train], feed_dict={X:x_data, Y:y_data})\n    if step % 500 == 0 :\n        print(\"#\", step, \"cost: \", cost_)\n        print(\"-total point: \", hypo_[0])","execution_count":25,"outputs":[{"output_type":"stream","text":"# 0 cost:  11148.105\n-total point:  [-41.033672]\n# 500 cost:  288.99332\n-total point:  [63.916237]\n# 1000 cost:  147.86066\n-total point:  [70.815056]\n# 1500 cost:  87.08135\n-total point:  [74.78616]\n# 2000 cost:  58.172184\n-total point:  [77.09043]\n# 2500 cost:  43.10178\n-total point:  [78.44432]\n# 3000 cost:  34.612682\n-total point:  [79.24863]\n# 3500 cost:  29.513771\n-total point:  [79.73227]\n# 4000 cost:  26.274014\n-total point:  [80.027565]\n# 4500 cost:  24.10174\n-total point:  [80.21153]\n# 5000 cost:  22.56337\n-total point:  [80.329254]\n# 5500 cost:  21.41153\n-total point:  [80.40706]\n# 6000 cost:  20.501032\n-total point:  [80.46056]\n# 6500 cost:  19.744843\n-total point:  [80.49895]\n# 7000 cost:  19.090075\n-total point:  [80.52752]\n# 7500 cost:  18.50394\n-total point:  [80.54936]\n# 8000 cost:  17.966082\n-total point:  [80.56674]\n# 8500 cost:  17.463581\n-total point:  [80.58071]\n# 9000 cost:  16.988089\n-total point:  [80.59208]\n# 9500 cost:  16.534195\n-total point:  [80.60134]\n# 10000 cost:  16.098253\n-total point:  [80.6087]\n# 10500 cost:  15.677886\n-total point:  [80.61459]\n# 11000 cost:  15.271288\n-total point:  [80.619095]\n# 11500 cost:  14.877254\n-total point:  [80.62239]\n# 12000 cost:  14.494868\n-total point:  [80.624756]\n# 12500 cost:  14.123398\n-total point:  [80.626144]\n# 13000 cost:  13.762287\n-total point:  [80.62672]\n# 13500 cost:  13.411092\n-total point:  [80.626625]\n# 14000 cost:  13.069372\n-total point:  [80.62579]\n# 14500 cost:  12.736817\n-total point:  [80.62463]\n# 15000 cost:  12.413123\n-total point:  [80.623116]\n# 15500 cost:  12.097952\n-total point:  [80.62105]\n# 16000 cost:  11.791056\n-total point:  [80.61877]\n# 16500 cost:  11.492241\n-total point:  [80.61603]\n# 17000 cost:  11.201223\n-total point:  [80.6132]\n# 17500 cost:  10.917749\n-total point:  [80.61021]\n# 18000 cost:  10.641695\n-total point:  [80.606926]\n# 18500 cost:  10.372787\n-total point:  [80.60343]\n# 19000 cost:  10.110863\n-total point:  [80.59999]\n# 19500 cost:  9.855707\n-total point:  [80.596214]\n# 20000 cost:  9.607166\n-total point:  [80.59261]\n# 20500 cost:  9.36504\n-total point:  [80.588806]\n# 21000 cost:  9.129158\n-total point:  [80.58496]\n# 21500 cost:  8.899376\n-total point:  [80.58121]\n# 22000 cost:  8.675473\n-total point:  [80.57725]\n# 22500 cost:  8.457348\n-total point:  [80.573135]\n# 23000 cost:  8.244856\n-total point:  [80.56951]\n# 23500 cost:  8.037778\n-total point:  [80.565315]\n# 24000 cost:  7.836019\n-total point:  [80.56115]\n# 24500 cost:  7.6394506\n-total point:  [80.55742]\n# 25000 cost:  7.447889\n-total point:  [80.5531]\n# 25500 cost:  7.2612433\n-total point:  [80.54928]\n# 26000 cost:  7.07936\n-total point:  [80.54512]\n# 26500 cost:  6.9021254\n-total point:  [80.54115]\n# 27000 cost:  6.7294207\n-total point:  [80.53722]\n# 27500 cost:  6.5611305\n-total point:  [80.53321]\n# 28000 cost:  6.3971205\n-total point:  [80.52925]\n# 28500 cost:  6.237295\n-total point:  [80.52526]\n# 29000 cost:  6.0815353\n-total point:  [80.52138]\n# 29500 cost:  5.929738\n-total point:  [80.51737]\n# 30000 cost:  5.781795\n-total point:  [80.51363]\n# 30500 cost:  5.6376324\n-total point:  [80.50962]\n# 31000 cost:  5.4971085\n-total point:  [80.50598]\n# 31500 cost:  5.3601584\n-total point:  [80.50205]\n# 32000 cost:  5.226672\n-total point:  [80.49834]\n# 32500 cost:  5.0965924\n-total point:  [80.49451]\n# 33000 cost:  4.9697685\n-total point:  [80.49054]\n# 33500 cost:  4.8461866\n-total point:  [80.486946]\n# 34000 cost:  4.7256994\n-total point:  [80.482864]\n# 34500 cost:  4.608251\n-total point:  [80.479256]\n# 35000 cost:  4.4937954\n-total point:  [80.47537]\n# 35500 cost:  4.382214\n-total point:  [80.471634]\n# 36000 cost:  4.2734456\n-total point:  [80.46785]\n# 36500 cost:  4.1674156\n-total point:  [80.464096]\n# 37000 cost:  4.064073\n-total point:  [80.46037]\n# 37500 cost:  3.9633405\n-total point:  [80.456764]\n# 38000 cost:  3.8651273\n-total point:  [80.45327]\n# 38500 cost:  3.769391\n-total point:  [80.44966]\n# 39000 cost:  3.676054\n-total point:  [80.44585]\n# 39500 cost:  3.5850587\n-total point:  [80.4424]\n# 40000 cost:  3.4963615\n-total point:  [80.438995]\n# 40500 cost:  3.4098613\n-total point:  [80.43498]\n# 41000 cost:  3.3255851\n-total point:  [80.43171]\n# 41500 cost:  3.2433574\n-total point:  [80.42824]\n# 42000 cost:  3.1632469\n-total point:  [80.42438]\n# 42500 cost:  3.0851176\n-total point:  [80.42095]\n# 43000 cost:  3.0089054\n-total point:  [80.41727]\n# 43500 cost:  2.93466\n-total point:  [80.41385]\n# 44000 cost:  2.862259\n-total point:  [80.41043]\n# 44500 cost:  2.7916512\n-total point:  [80.40687]\n# 45000 cost:  2.72278\n-total point:  [80.40364]\n# 45500 cost:  2.6556916\n-total point:  [80.40014]\n# 46000 cost:  2.5902658\n-total point:  [80.39671]\n# 46500 cost:  2.5264633\n-total point:  [80.39344]\n# 47000 cost:  2.4642353\n-total point:  [80.38994]\n# 47500 cost:  2.4035287\n-total point:  [80.38677]\n# 48000 cost:  2.3443854\n-total point:  [80.3836]\n# 48500 cost:  2.2867343\n-total point:  [80.38015]\n# 49000 cost:  2.2304695\n-total point:  [80.37656]\n# 49500 cost:  2.1756332\n-total point:  [80.3735]\n# 50000 cost:  2.1221492\n-total point:  [80.370415]\n# 50500 cost:  2.0699847\n-total point:  [80.36686]\n# 51000 cost:  2.0191262\n-total point:  [80.3636]\n# 51500 cost:  1.969518\n-total point:  [80.36037]\n# 52000 cost:  1.9211512\n-total point:  [80.35714]\n# 52500 cost:  1.8739753\n-total point:  [80.35402]\n# 53000 cost:  1.827981\n-total point:  [80.35079]\n# 53500 cost:  1.7831192\n-total point:  [80.347755]\n# 54000 cost:  1.7393782\n-total point:  [80.344635]\n# 54500 cost:  1.6967202\n-total point:  [80.34163]\n# 55000 cost:  1.65513\n-total point:  [80.33842]\n# 55500 cost:  1.6145482\n-total point:  [80.33537]\n# 56000 cost:  1.5749644\n-total point:  [80.332466]\n# 56500 cost:  1.5363616\n-total point:  [80.32957]\n# 57000 cost:  1.4987293\n-total point:  [80.32661]\n# 57500 cost:  1.4619969\n-total point:  [80.32351]\n# 58000 cost:  1.4262229\n-total point:  [80.320305]\n# 58500 cost:  1.3913208\n-total point:  [80.31737]\n# 59000 cost:  1.3572733\n-total point:  [80.31456]\n# 59500 cost:  1.3240553\n-total point:  [80.31152]\n# 60000 cost:  1.2916361\n-total point:  [80.30857]\n# 60500 cost:  1.2600198\n-total point:  [80.30582]\n# 61000 cost:  1.2292383\n-total point:  [80.30276]\n# 61500 cost:  1.1991965\n-total point:  [80.300095]\n# 62000 cost:  1.1698874\n-total point:  [80.29722]\n# 62500 cost:  1.1412622\n-total point:  [80.29441]\n# 63000 cost:  1.1133825\n-total point:  [80.29181]\n# 63500 cost:  1.0862181\n-total point:  [80.28886]\n# 64000 cost:  1.0596863\n-total point:  [80.28622]\n# 64500 cost:  1.0337625\n-total point:  [80.283585]\n# 65000 cost:  1.0085471\n-total point:  [80.28097]\n# 65500 cost:  0.9839462\n-total point:  [80.27838]\n# 66000 cost:  0.95992565\n-total point:  [80.27572]\n# 66500 cost:  0.9364877\n-total point:  [80.27301]\n# 67000 cost:  0.9136701\n-total point:  [80.27004]\n# 67500 cost:  0.8913612\n-total point:  [80.26746]\n# 68000 cost:  0.8696152\n-total point:  [80.264885]\n# 68500 cost:  0.8484318\n-total point:  [80.26241]\n# 69000 cost:  0.82771844\n-total point:  [80.259834]\n# 69500 cost:  0.80755436\n-total point:  [80.25718]\n# 70000 cost:  0.78787667\n-total point:  [80.254715]\n# 70500 cost:  0.76862764\n-total point:  [80.25233]\n# 71000 cost:  0.74994963\n-total point:  [80.24973]\n# 71500 cost:  0.7316601\n-total point:  [80.247284]\n# 72000 cost:  0.71384203\n-total point:  [80.24499]\n# 72500 cost:  0.69647574\n-total point:  [80.242645]\n# 73000 cost:  0.67947364\n-total point:  [80.24035]\n# 73500 cost:  0.66298145\n-total point:  [80.23795]\n# 74000 cost:  0.64681864\n-total point:  [80.23567]\n# 74500 cost:  0.6311066\n-total point:  [80.23326]\n# 75000 cost:  0.6157355\n-total point:  [80.230606]\n# 75500 cost:  0.60076916\n-total point:  [80.22825]\n# 76000 cost:  0.58613557\n-total point:  [80.226036]\n# 76500 cost:  0.5718847\n-total point:  [80.223885]\n# 77000 cost:  0.5579818\n-total point:  [80.221756]\n# 77500 cost:  0.5444062\n-total point:  [80.2196]\n# 78000 cost:  0.5311778\n-total point:  [80.21742]\n# 78500 cost:  0.5182534\n-total point:  [80.21524]\n# 79000 cost:  0.5056695\n-total point:  [80.21272]\n# 79500 cost:  0.49337834\n-total point:  [80.210625]\n# 80000 cost:  0.48138252\n-total point:  [80.20851]\n","name":"stdout"},{"output_type":"stream","text":"# 80500 cost:  0.46969682\n-total point:  [80.20654]\n# 81000 cost:  0.45827278\n-total point:  [80.204185]\n# 81500 cost:  0.44716895\n-total point:  [80.202156]\n# 82000 cost:  0.4362639\n-total point:  [80.20016]\n# 82500 cost:  0.42571524\n-total point:  [80.198235]\n# 83000 cost:  0.41533586\n-total point:  [80.19625]\n# 83500 cost:  0.40529415\n-total point:  [80.194046]\n# 84000 cost:  0.3954404\n-total point:  [80.19219]\n# 84500 cost:  0.3858468\n-total point:  [80.190315]\n# 85000 cost:  0.37649512\n-total point:  [80.18845]\n# 85500 cost:  0.36733484\n-total point:  [80.18646]\n# 86000 cost:  0.35846823\n-total point:  [80.18412]\n# 86500 cost:  0.34974545\n-total point:  [80.18228]\n# 87000 cost:  0.341253\n-total point:  [80.1804]\n# 87500 cost:  0.33299044\n-total point:  [80.17857]\n# 88000 cost:  0.3248606\n-total point:  [80.17674]\n# 88500 cost:  0.31703135\n-total point:  [80.17501]\n# 89000 cost:  0.3093306\n-total point:  [80.17327]\n# 89500 cost:  0.30181918\n-total point:  [80.1715]\n# 90000 cost:  0.29453146\n-total point:  [80.16972]\n# 90500 cost:  0.28736025\n-total point:  [80.16792]\n# 91000 cost:  0.28040457\n-total point:  [80.16596]\n# 91500 cost:  0.273624\n-total point:  [80.16408]\n# 92000 cost:  0.2669539\n-total point:  [80.16235]\n# 92500 cost:  0.26049724\n-total point:  [80.1607]\n# 93000 cost:  0.2541991\n-total point:  [80.159065]\n# 93500 cost:  0.24800415\n-total point:  [80.15746]\n# 94000 cost:  0.24201868\n-total point:  [80.15567]\n# 94500 cost:  0.23617242\n-total point:  [80.15401]\n# 95000 cost:  0.23042437\n-total point:  [80.15235]\n# 95500 cost:  0.2248431\n-total point:  [80.15078]\n# 96000 cost:  0.21942005\n-total point:  [80.14929]\n# 96500 cost:  0.21408929\n-total point:  [80.14775]\n# 97000 cost:  0.20889519\n-total point:  [80.146225]\n# 97500 cost:  0.20386736\n-total point:  [80.14472]\n# 98000 cost:  0.19892184\n-total point:  [80.143166]\n# 98500 cost:  0.19406053\n-total point:  [80.14159]\n# 99000 cost:  0.18940398\n-total point:  [80.14012]\n# 99500 cost:  0.18482749\n-total point:  [80.138664]\n# 100000 cost:  0.1803288\n-total point:  [80.13719]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"saver = tf.compat.v1.train.Saver()\nsave_path = saver.save(sess, \"./saved.cpkt\")\nprint(\"model saved\")","execution_count":26,"outputs":[{"output_type":"stream","text":"model saved\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"saver = tf.compat.v1.train.Saver()\nmodel = tf.compat.v1.global_variables_initializer()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"speed = float(input('speed: '))\nplay_passing = float(input('play_passing: '))\ncreation_passing = float(input('creation_passing: '))\ncreation_crossing = float(input('creation_crossing: '))\ncreation_shooting = float(input('creation_shooting: '))\npressure = float(input('pressure: '))\naggression = float(input('agression: '))\nteamwidth = float(input('teamwidth: '))\nwins = float(input('wins: '))\ndraws = float(input('draws: '))\nloses = float(input('loses: '))\ngoals_scored = float(input('goals_scored: '))\ngoals_against = float(input('goals_against: '))\ngoal_diff = float(input('goal_diff: '))","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":"speed: 63\nplay_passing: 60\ncreation_passing: 47\ncreation_crossing: 64\ncreation_shooting: 46\npressure: 58\nagression: 65\nteamwidth: 55\nwins: 23\ndraws: 12\nloses: 3\ngoals_scored: 68\ngoals_against: 36\ngoal_diff: 32\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.compat.v1.Session() as sess: \n    sess.run(model)\n    save_path = \"./saved.cpkt\"\n    saver.restore(sess, save_path)\n\n    data = ((speed, play_passing, creation_passing, creation_crossing, creation_shooting, pressure, aggression, teamwidth, wins, draws, loses, goals_scored, goals_against, goal_diff),)\n    arr = np.array(data, dtype=np.float32)\n\n    x_data = arr[0:14]\n    dict = sess.run(hypothesis, feed_dict={X:x_data})\n    print(dict[0])","execution_count":29,"outputs":[{"output_type":"stream","text":"[80.94755]\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}